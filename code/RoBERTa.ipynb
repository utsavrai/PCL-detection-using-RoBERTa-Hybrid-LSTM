{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RoBERTa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "HF_TOKEN = \"put your token here\"\n",
    "WANDB_TOKEN = \"put your token here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!source ~/.bashrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!huggingface-cli login --token={HF_TOKEN}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "# WANDB_TOKEN = userdata.get('WANDB_TOKEN')\n",
    "wandb.login(key=WANDB_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    RobertaTokenizerFast,\n",
    "    RobertaForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    AutoConfig,\n",
    ")\n",
    "from huggingface_hub import HfFolder, notebook_login\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1 - RoBERTa Base on Unprocessed Text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"roberta-base\"\n",
    "dataset_id = \"ImperialIndians23/nlp_cw_data_unprocessed\"\n",
    "repository_id = \"ImperialIndians23/RobertaBaseUnprocessed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset - Load and Tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and testing datasets\n",
    "train_dataset = dataset[\"train\"]\n",
    "\n",
    "# Validation dataset\n",
    "val_dataset = dataset[\"valid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(model_id)\n",
    "\n",
    "\n",
    "# This function tokenizes the input text using the RoBERTa tokenizer.\n",
    "# It applies padding and truncation to ensure that all sequences have the same length (512 tokens).\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True, max_length=512)\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "val_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter(dataset[\"train\"][\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = 2\n",
    "class_names = [0, 1]\n",
    "print(f\"number of labels: {num_labels}\")\n",
    "print(f\"the labels: {class_names}\")\n",
    "\n",
    "id2label = {i: label for i, label in enumerate(class_names)}\n",
    "\n",
    "# Update the model's configuration with the id2label mapping\n",
    "config = AutoConfig.from_pretrained(model_id)\n",
    "config.update({\"id2label\": id2label})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    precision_recall_fscore_support,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "from transformers import EvalPrediction\n",
    "\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions.argmax(-1)\n",
    "    labels = p.label_ids\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds)\n",
    "    recall = recall_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds)\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"f1\": f1,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model - Definition and Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RobertaForSequenceClassification.from_pretrained(model_id, config=config)\n",
    "\n",
    "training_config = {\n",
    "    \"learning_rate\": 1e-5,\n",
    "    \"num_train_epochs\": 3,\n",
    "    \"weight_decay\": 0.01,\n",
    "    \"gradient_accumulation_steps\": 4,\n",
    "    \"per_device_train_batch_size\": 4,\n",
    "    \"per_device_eval_batch_size\": 2,\n",
    "    \"lr_scheduler_type\": \"inverse_sqrt\",\n",
    "    \"warmup_steps\": 500,\n",
    "    \"load_best_model_at_end\": True,\n",
    "    \"save_strategy\": \"epoch\",\n",
    "    \"evaluation_strategy\": \"epoch\",\n",
    "    \"metric_for_best_model\": \"f1\",\n",
    "}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=repository_id,\n",
    "    logging_dir=f\"{repository_id}/logs\",\n",
    "    logging_steps=10,\n",
    "    save_total_limit=3,\n",
    "    push_to_hub=True,\n",
    "    report_to=\"wandb\",\n",
    "    **training_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(\n",
    "    project=\"nlp_cw\",\n",
    "    name=\"roberta - unprocessed text - 3 epochs -1e-5 lr\",\n",
    "    # Track hyperparameters and run metadata\n",
    "    config=training_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the tokenizer and create a model card\n",
    "tokenizer.save_pretrained(repository_id)\n",
    "trainer.create_model_card()\n",
    "\n",
    "# Push the results to the hub\n",
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset = dataset[\"valid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "\n",
    "classifier = pipeline(\"text-classification\", repository_id)\n",
    "\n",
    "batch_size = 4\n",
    "predictions = []\n",
    "\n",
    "# Retrieve all texts from the dataset\n",
    "texts = [example[\"text\"] for example in valid_dataset]\n",
    "\n",
    "# Process texts in batches\n",
    "for i in range(0, len(texts), batch_size):\n",
    "    batch_texts = texts[i : i + batch_size]\n",
    "    batch_results = classifier(batch_texts)\n",
    "\n",
    "    # Extract and store predictions from results\n",
    "    batch_predictions = [result[\"label\"] for result in batch_results]\n",
    "    predictions.extend(batch_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    precision_recall_fscore_support,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "gold = dataset[\"valid\"][\"label\"]\n",
    "t1p = precision_score(gold, predictions)\n",
    "t1r = recall_score(gold, predictions)\n",
    "t1f = f1_score(gold, predictions)\n",
    "print(\"Precision:\", t1p)\n",
    "print(\"Recall:\", t1r)\n",
    "print(\"F1:\", t1f)\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2 : Downsample Negative Samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"ImperialIndians23/nlp_cw_data_unprocessed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict, Dataset, concatenate_datasets\n",
    "import random\n",
    "\n",
    "train_dataset = dataset[\"train\"]\n",
    "\n",
    "# Separate the dataset by label\n",
    "label_0_dataset = train_dataset.filter(lambda example: example[\"label\"] == 0)\n",
    "label_1_dataset = train_dataset.filter(lambda example: example[\"label\"] == 1)\n",
    "\n",
    "num_label_1 = len(label_1_dataset)\n",
    "\n",
    "desired_num_label_0 = 2 * num_label_1\n",
    "\n",
    "random.seed(42)\n",
    "downsampled_label_0_indices = random.sample(\n",
    "    range(len(label_0_dataset)), k=desired_num_label_0\n",
    ")\n",
    "\n",
    "downsampled_label_0_dataset = label_0_dataset.select(downsampled_label_0_indices)\n",
    "\n",
    "# Concatenate downsampled label 0 dataset with label 1 dataset\n",
    "balanced_train_dataset = concatenate_datasets(\n",
    "    [downsampled_label_0_dataset, label_1_dataset]\n",
    ")\n",
    "\n",
    "dataset[\"train\"] = balanced_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.push_to_hub(\"ImperialIndians23/nlp_cw_data_unprocessed_downsampled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    RobertaTokenizerFast,\n",
    "    RobertaForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    AutoConfig,\n",
    ")\n",
    "from huggingface_hub import HfFolder, notebook_login\n",
    "from tqdm import tqdm\n",
    "\n",
    "import wandb\n",
    "import os\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_fscore_support,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "from transformers import EvalPrediction\n",
    "\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions.argmax(-1)\n",
    "    labels = p.label_ids\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds)\n",
    "    recall = recall_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds)\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"f1\": f1,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "    }\n",
    "\n",
    "\n",
    "HF_TOKEN = \"put your token here\"\n",
    "WANDB_TOKEN = \"put your token here\"\n",
    "\n",
    "# WANDB_TOKEN = userdata.get('WANDB_TOKEN')\n",
    "wandb.login(key=WANDB_TOKEN)\n",
    "\n",
    "model_id = \"roberta-base\"\n",
    "username = \"ImperialIndians23\"\n",
    "dataset_id = \"ImperialIndians23/nlp_cw_data_unprocessed_downsampled\"\n",
    "\n",
    "repository_id = \"ImperialIndians23/RobertaBaseUnprocessedDownsampledLowLR\"\n",
    "\n",
    "dataset = load_dataset(dataset_id)\n",
    "\n",
    "print(\"Processing the dataset...\")\n",
    "\n",
    "# Training and testing datasets\n",
    "train_dataset = dataset[\"train\"]\n",
    "test_dataset = dataset[\"valid\"].shard(num_shards=2, index=0)\n",
    "\n",
    "# Validation dataset\n",
    "val_dataset = dataset[\"valid\"].shard(num_shards=2, index=1)\n",
    "\n",
    "# Preprocessing\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(model_id)\n",
    "\n",
    "\n",
    "# This function tokenizes the input text using the RoBERTa tokenizer.\n",
    "# It applies padding and truncation to ensure that all sequences have the same length (512 tokens).\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True, max_length=512)\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize, batched=True, batch_size=len(train_dataset))\n",
    "val_dataset = val_dataset.map(tokenize, batched=True, batch_size=len(val_dataset))\n",
    "test_dataset = test_dataset.map(tokenize, batched=True, batch_size=len(test_dataset))\n",
    "\n",
    "train_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "val_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "test_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "num_labels = 2\n",
    "class_names = [0, 1]\n",
    "print(f\"number of labels: {num_labels}\")\n",
    "print(f\"the labels: {class_names}\")\n",
    "\n",
    "id2label = {i: label for i, label in enumerate(class_names)}\n",
    "\n",
    "# Update the model's configuration with the id2label mapping\n",
    "config = AutoConfig.from_pretrained(model_id)\n",
    "config.update({\"id2label\": id2label})\n",
    "\n",
    "\n",
    "model = RobertaForSequenceClassification.from_pretrained(model_id, config=config)\n",
    "\n",
    "training_config = {\n",
    "    \"learning_rate\": 1e-5,\n",
    "    \"num_train_epochs\": 2,\n",
    "    \"weight_decay\": 0.01,\n",
    "    \"gradient_accumulation_steps\": 4,\n",
    "    \"per_device_train_batch_size\": 4,\n",
    "    \"per_device_eval_batch_size\": 2,\n",
    "    \"lr_scheduler_type\": \"inverse_sqrt\",\n",
    "    \"warmup_steps\": 500,\n",
    "    \"load_best_model_at_end\": True,\n",
    "    \"save_strategy\": \"epoch\",\n",
    "    \"evaluation_strategy\": \"epoch\",\n",
    "    \"metric_for_best_model\": \"f1\",\n",
    "}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=repository_id,\n",
    "    logging_dir=f\"{repository_id}/logs\",\n",
    "    logging_steps=10,\n",
    "    save_total_limit=3,\n",
    "    push_to_hub=True,\n",
    "    report_to=\"wandb\",\n",
    "    **training_config,\n",
    ")\n",
    "\n",
    "run = wandb.init(\n",
    "    project=\"nlp_cw\",\n",
    "    name=f\"roberta - {dataset_id.strip(username)} - {training_config['num_train_epochs']} epochs - {training_config['learning_rate']}\",\n",
    "    # Track hyperparameters and run metadata\n",
    "    config=training_config,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "trainer.evaluate()\n",
    "\n",
    "# Save the tokenizer and create a model card\n",
    "tokenizer.save_pretrained(repository_id)\n",
    "trainer.create_model_card()\n",
    "\n",
    "# Push the results to the hub\n",
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3 - Processed Text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    RobertaTokenizerFast,\n",
    "    RobertaForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    AutoConfig,\n",
    ")\n",
    "from huggingface_hub import HfFolder, notebook_login\n",
    "from tqdm import tqdm\n",
    "\n",
    "import wandb\n",
    "import os\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_fscore_support,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "from transformers import EvalPrediction\n",
    "\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions.argmax(-1)\n",
    "    labels = p.label_ids\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds)\n",
    "    recall = recall_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds)\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"f1\": f1,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "    }\n",
    "\n",
    "\n",
    "HF_TOKEN = \"put your token here\"\n",
    "WANDB_TOKEN = \"put your token here\"\n",
    "\n",
    "# WANDB_TOKEN = userdata.get('WANDB_TOKEN')\n",
    "wandb.login(key=WANDB_TOKEN)\n",
    "\n",
    "model_id = \"roberta-base\"\n",
    "username = \"ImperialIndians23/\"\n",
    "dataset_id = \"ImperialIndians23/nlp_cw_data_processed\"\n",
    "\n",
    "repository_id = \"ImperialIndians23/RobertaBaseProcessed\"\n",
    "\n",
    "dataset = load_dataset(dataset_id)\n",
    "\n",
    "print(\"Processing the dataset...\")\n",
    "\n",
    "# Training and testing datasets\n",
    "train_dataset = dataset[\"train\"]\n",
    "\n",
    "# Validation dataset\n",
    "val_dataset = dataset[\"valid\"]\n",
    "\n",
    "# Preprocessing\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(model_id)\n",
    "\n",
    "\n",
    "# This function tokenizes the input text using the RoBERTa tokenizer.\n",
    "# It applies padding and truncation to ensure that all sequences have the same length (512 tokens).\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True, max_length=512)\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize, batched=True, batch_size=len(train_dataset))\n",
    "val_dataset = val_dataset.map(tokenize, batched=True, batch_size=len(val_dataset))\n",
    "\n",
    "train_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "val_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "num_labels = 2\n",
    "class_names = [0, 1]\n",
    "print(f\"number of labels: {num_labels}\")\n",
    "print(f\"the labels: {class_names}\")\n",
    "\n",
    "id2label = {i: label for i, label in enumerate(class_names)}\n",
    "\n",
    "# Update the model's configuration with the id2label mapping\n",
    "config = AutoConfig.from_pretrained(model_id)\n",
    "config.update({\"id2label\": id2label})\n",
    "\n",
    "\n",
    "model = RobertaForSequenceClassification.from_pretrained(model_id, config=config)\n",
    "\n",
    "training_config = {\n",
    "    \"learning_rate\": 1e-5,\n",
    "    \"num_train_epochs\": 2,\n",
    "    \"weight_decay\": 0.01,\n",
    "    \"gradient_accumulation_steps\": 4,\n",
    "    \"per_device_train_batch_size\": 4,\n",
    "    \"per_device_eval_batch_size\": 2,\n",
    "    \"lr_scheduler_type\": \"inverse_sqrt\",\n",
    "    \"warmup_steps\": 500,\n",
    "    \"load_best_model_at_end\": True,\n",
    "    \"save_strategy\": \"epoch\",\n",
    "    \"evaluation_strategy\": \"epoch\",\n",
    "    \"metric_for_best_model\": \"f1\",\n",
    "}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=repository_id,\n",
    "    logging_dir=f\"{repository_id}/logs\",\n",
    "    logging_steps=10,\n",
    "    save_total_limit=3,\n",
    "    push_to_hub=True,\n",
    "    report_to=\"wandb\",\n",
    "    **training_config,\n",
    ")\n",
    "\n",
    "run = wandb.init(\n",
    "    project=\"nlp_cw\",\n",
    "    name=f\"roberta - {dataset_id.strip(username)} - {training_config['num_train_epochs']} epochs - {training_config['learning_rate']}\",\n",
    "    # Track hyperparameters and run metadata\n",
    "    config=training_config,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "trainer.evaluate()\n",
    "\n",
    "# Save the tokenizer and create a model card\n",
    "tokenizer.save_pretrained(repository_id)\n",
    "trainer.create_model_card()\n",
    "\n",
    "# Push the results to the hub\n",
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 4 - Down Sampling Processed Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"ImperialIndians23/nlp_cw_data_processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict, Dataset, concatenate_datasets\n",
    "import random\n",
    "\n",
    "train_dataset = dataset[\"train\"]\n",
    "\n",
    "# Separate the dataset by label\n",
    "label_0_dataset = train_dataset.filter(lambda example: example[\"label\"] == 0)\n",
    "label_1_dataset = train_dataset.filter(lambda example: example[\"label\"] == 1)\n",
    "\n",
    "num_label_1 = len(label_1_dataset)\n",
    "\n",
    "desired_num_label_0 = 2 * num_label_1\n",
    "\n",
    "random.seed(42)\n",
    "downsampled_label_0_indices = random.sample(\n",
    "    range(len(label_0_dataset)), k=desired_num_label_0\n",
    ")\n",
    "\n",
    "downsampled_label_0_dataset = label_0_dataset.select(downsampled_label_0_indices)\n",
    "\n",
    "# Concatenate downsampled label 0 dataset with label 1 dataset\n",
    "balanced_train_dataset = concatenate_datasets(\n",
    "    [downsampled_label_0_dataset, label_1_dataset]\n",
    ")\n",
    "\n",
    "dataset[\"train\"] = balanced_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.push_to_hub(\"ImperialIndians23/nlp_cw_data_processed_downsampled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    RobertaTokenizerFast,\n",
    "    RobertaForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    AutoConfig,\n",
    ")\n",
    "from huggingface_hub import HfFolder, notebook_login\n",
    "from tqdm import tqdm\n",
    "\n",
    "import wandb\n",
    "import os\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_fscore_support,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "from transformers import EvalPrediction\n",
    "\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions.argmax(-1)\n",
    "    labels = p.label_ids\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds)\n",
    "    recall = recall_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds)\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"f1\": f1,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "    }\n",
    "\n",
    "\n",
    "HF_TOKEN = \"put your token here\"\n",
    "WANDB_TOKEN = \"put your token here\"\n",
    "\n",
    "# WANDB_TOKEN = userdata.get('WANDB_TOKEN')\n",
    "wandb.login(key=WANDB_TOKEN)\n",
    "\n",
    "model_id = \"roberta-base\"\n",
    "username = \"ImperialIndians23/\"\n",
    "dataset_id = \"ImperialIndians23/nlp_cw_data_processed_downsampled\"\n",
    "\n",
    "repository_id = \"ImperialIndians23/RobertaBaseProcessedDownsampled\"\n",
    "\n",
    "dataset = load_dataset(dataset_id)\n",
    "\n",
    "print(\"Processing the dataset...\")\n",
    "\n",
    "# Training and testing datasets\n",
    "train_dataset = dataset[\"train\"]\n",
    "test_dataset = dataset[\"valid\"].shard(num_shards=2, index=0)\n",
    "\n",
    "# Validation dataset\n",
    "val_dataset = dataset[\"valid\"].shard(num_shards=2, index=1)\n",
    "\n",
    "# Preprocessing\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(model_id)\n",
    "\n",
    "\n",
    "# This function tokenizes the input text using the RoBERTa tokenizer.\n",
    "# It applies padding and truncation to ensure that all sequences have the same length (512 tokens).\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True, max_length=512)\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize, batched=True, batch_size=len(train_dataset))\n",
    "val_dataset = val_dataset.map(tokenize, batched=True, batch_size=len(val_dataset))\n",
    "test_dataset = test_dataset.map(tokenize, batched=True, batch_size=len(test_dataset))\n",
    "\n",
    "train_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "val_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "test_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "num_labels = 2\n",
    "class_names = [0, 1]\n",
    "print(f\"number of labels: {num_labels}\")\n",
    "print(f\"the labels: {class_names}\")\n",
    "\n",
    "id2label = {i: label for i, label in enumerate(class_names)}\n",
    "\n",
    "# Update the model's configuration with the id2label mapping\n",
    "config = AutoConfig.from_pretrained(model_id)\n",
    "config.update({\"id2label\": id2label})\n",
    "\n",
    "\n",
    "model = RobertaForSequenceClassification.from_pretrained(model_id, config=config)\n",
    "\n",
    "training_config = {\n",
    "    \"learning_rate\": 1e-5,\n",
    "    \"num_train_epochs\": 4,\n",
    "    \"weight_decay\": 0.01,\n",
    "    \"gradient_accumulation_steps\": 4,\n",
    "    \"per_device_train_batch_size\": 4,\n",
    "    \"per_device_eval_batch_size\": 2,\n",
    "    \"lr_scheduler_type\": \"inverse_sqrt\",\n",
    "    \"warmup_steps\": 500,\n",
    "    \"load_best_model_at_end\": True,\n",
    "    \"save_strategy\": \"epoch\",\n",
    "    \"evaluation_strategy\": \"epoch\",\n",
    "    \"metric_for_best_model\": \"f1\",\n",
    "}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=repository_id,\n",
    "    logging_dir=f\"{repository_id}/logs\",\n",
    "    logging_steps=10,\n",
    "    save_total_limit=3,\n",
    "    push_to_hub=True,\n",
    "    report_to=\"wandb\",\n",
    "    **training_config,\n",
    ")\n",
    "\n",
    "run = wandb.init(\n",
    "    project=\"nlp_cw\",\n",
    "    name=f\"roberta - {dataset_id.strip(username)} - {training_config['num_train_epochs']} epochs - {training_config['learning_rate']}\",\n",
    "    # Track hyperparameters and run metadata\n",
    "    config=training_config,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "trainer.evaluate()\n",
    "\n",
    "# Save the tokenizer and create a model card\n",
    "tokenizer.save_pretrained(repository_id)\n",
    "trainer.create_model_card()\n",
    "\n",
    "# Push the results to the hub\n",
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 5 - Custom RoBERTa model - Unprocessed Text (Downsampled) + Keyword\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    RobertaTokenizerFast,\n",
    "    RobertaForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    AutoConfig,\n",
    ")\n",
    "from huggingface_hub import HfFolder, notebook_login\n",
    "from tqdm import tqdm\n",
    "\n",
    "import wandb\n",
    "import os\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_fscore_support,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "from transformers import EvalPrediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"ImperialIndians23/nlp_cw_data_processed_downsampled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Embeddings for Community Keywords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizerFast\n",
    "\n",
    "model_id = \"roberta-base\"\n",
    "\n",
    "\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(model_id)\n",
    "\n",
    "\n",
    "def tokenize_data(batch):\n",
    "    # Tokenize the main text\n",
    "    text_encoding = tokenizer(\n",
    "        batch[\"text\"],\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    # Tokenize the community keyword\n",
    "    community_encoding = tokenizer(\n",
    "        batch[\"community\"],\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=64,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": text_encoding[\"input_ids\"],\n",
    "        \"attention_mask\": text_encoding[\"attention_mask\"],\n",
    "        \"community_input_ids\": community_encoding[\"input_ids\"],\n",
    "        \"community_attention_mask\": community_encoding[\"attention_mask\"],\n",
    "    }\n",
    "\n",
    "\n",
    "dataset[\"train\"] = dataset[\"train\"].map(tokenize_data, batched=True)\n",
    "dataset[\"valid\"] = dataset[\"valid\"].map(tokenize_data, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train\"].set_format(\n",
    "    \"torch\",\n",
    "    columns=[\n",
    "        \"input_ids\",\n",
    "        \"attention_mask\",\n",
    "        \"label\",\n",
    "        \"community_input_ids\",\n",
    "        \"community_attention_mask\",\n",
    "    ],\n",
    ")\n",
    "dataset[\"valid\"].set_format(\n",
    "    \"torch\",\n",
    "    columns=[\n",
    "        \"input_ids\",\n",
    "        \"attention_mask\",\n",
    "        \"label\",\n",
    "        \"community_input_ids\",\n",
    "        \"community_attention_mask\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "import torch\n",
    "\n",
    "\n",
    "class CustomDataCollatorWithPadding(DataCollatorWithPadding):\n",
    "    def __call__(self, features):\n",
    "        batch = super().__call__(features)\n",
    "\n",
    "        community_input_ids = torch.stack(\n",
    "            [feature[\"community_input_ids\"] for feature in features]\n",
    "        )\n",
    "        community_attention_mask = torch.stack(\n",
    "            [feature[\"community_attention_mask\"] for feature in features]\n",
    "        )\n",
    "\n",
    "        padded_community_input_ids = self.pad_tensors(\n",
    "            community_input_ids, self.tokenizer.pad_token_id\n",
    "        )\n",
    "        padded_community_attention_mask = self.pad_tensors(community_attention_mask, 0)\n",
    "\n",
    "        batch[\"community_input_ids\"] = padded_community_input_ids\n",
    "        batch[\"community_attention_mask\"] = padded_community_attention_mask\n",
    "\n",
    "        return batch\n",
    "\n",
    "    def pad_tensors(self, tensors, pad_token_id):\n",
    "        max_length = max(t.size(0) for t in tensors)\n",
    "        # Pad each tensor to match the longest one\n",
    "        padded = torch.stack(\n",
    "            [\n",
    "                torch.cat(\n",
    "                    [\n",
    "                        t,\n",
    "                        torch.full(\n",
    "                            (max_length - t.size(0),), pad_token_id, dtype=t.dtype\n",
    "                        ),\n",
    "                    ]\n",
    "                )\n",
    "                for t in tensors\n",
    "            ]\n",
    "        )\n",
    "        return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import RobertaModel, RobertaTokenizer, AdamW\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "class RobertaClassifier(nn.Module):\n",
    "    def __init__(self, num_labels, config):\n",
    "        super(RobertaClassifier, self).__init__()\n",
    "        self.roberta = RobertaModel.from_pretrained(\"roberta-base\", config=config)\n",
    "        self.mapper = nn.Linear(\n",
    "            self.roberta.config.hidden_size * 2, self.roberta.config.hidden_size * 2\n",
    "        )\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.classifier = nn.Linear(self.roberta.config.hidden_size * 2, num_labels)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.config = config\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids,\n",
    "        attention_mask,\n",
    "        community_input_ids,\n",
    "        community_attention_mask,\n",
    "        labels=None,\n",
    "    ):\n",
    "        outputs = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        text_embedding = outputs[1]\n",
    "\n",
    "        # Process community keywords\n",
    "        community_outputs = self.roberta(\n",
    "            input_ids=community_input_ids, attention_mask=community_attention_mask\n",
    "        )\n",
    "        community_embedding = community_outputs[1]\n",
    "\n",
    "        # print(f\"Text embedding shape: {text_embedding.shape}\")\n",
    "        # print(f\"Community embedding shape: {community_embedding.shape}\")\n",
    "\n",
    "        # Concatenate\n",
    "        combined_embedding = torch.cat((text_embedding, community_embedding), dim=1)\n",
    "\n",
    "        mapped_embedding = self.mapper(combined_embedding)\n",
    "        # Apply dropout to the output of the mapper\n",
    "        dropped_embedding = self.dropout(mapped_embedding)\n",
    "\n",
    "        # Pass the result through the classifier to get logits\n",
    "        logits = self.classifier(dropped_embedding)\n",
    "\n",
    "        # Compute loss if labels are provided (during training)\n",
    "        if labels is not None:\n",
    "            loss = self.loss_fn(logits, labels)\n",
    "            return loss, logits\n",
    "        else:\n",
    "            return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = 2\n",
    "class_names = [0, 1]\n",
    "print(f\"number of labels: {num_labels}\")\n",
    "print(f\"the labels: {class_names}\")\n",
    "\n",
    "id2label = {i: label for i, label in enumerate(class_names)}\n",
    "\n",
    "# Update the model's configuration with the id2label mapping\n",
    "config = AutoConfig.from_pretrained(\"roberta-base\")\n",
    "config.update({\"id2label\": id2label})\n",
    "\n",
    "model = RobertaClassifier(num_labels=2, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    precision_recall_fscore_support,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "from transformers import EvalPrediction\n",
    "\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions.argmax(-1)\n",
    "    labels = p.label_ids\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds)\n",
    "    recall = recall_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds)\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"f1\": f1,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"roberta-base\"\n",
    "username = \"ImperialIndians23/\"\n",
    "dataset_id = \"ImperialIndians23/nlp_cw_data_unprocessed_downsampled_keyword\"\n",
    "\n",
    "repository_id = \"ImperialIndians23/RobertaBaseUnprocessedDownsampledKeywordDropout\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "WANDB_TOKEN = \"put your token here\"\n",
    "\n",
    "# WANDB_TOKEN = userdata.get('WANDB_TOKEN')\n",
    "wandb.login(key=WANDB_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_config = {\n",
    "    \"learning_rate\": 1e-5,\n",
    "    \"num_train_epochs\": 3,\n",
    "    \"weight_decay\": 0.01,\n",
    "    \"gradient_accumulation_steps\": 4,\n",
    "    \"per_device_train_batch_size\": 4,\n",
    "    \"per_device_eval_batch_size\": 2,\n",
    "    \"lr_scheduler_type\": \"inverse_sqrt\",\n",
    "    \"warmup_steps\": 500,\n",
    "    \"load_best_model_at_end\": True,\n",
    "    \"save_strategy\": \"epoch\",\n",
    "    \"evaluation_strategy\": \"epoch\",\n",
    "    \"metric_for_best_model\": \"f1\",\n",
    "}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=repository_id,\n",
    "    logging_dir=f\"{repository_id}/logs\",\n",
    "    logging_steps=10,\n",
    "    save_total_limit=3,\n",
    "    push_to_hub=True,\n",
    "    report_to=\"wandb\",\n",
    "    **training_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(\n",
    "    project=\"nlp_cw\",\n",
    "    name=f\"roberta - keyword unprocessed downsampled dropout - {training_config['num_train_epochs']} epochs\",\n",
    "    # Track hyperparameters and run metadata\n",
    "    config=training_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = CustomDataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"valid\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(\n",
    "    trainer.model.state_dict(),\n",
    "    \"./nlp/ImperialIndians23/RobertaBaseUnprocessedDownsampledKeyword/final_model.pth\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()\n",
    "\n",
    "# Save the tokenizer and create a model card\n",
    "model.save_pretrained(repository_id)\n",
    "tokenizer.save_pretrained(repository_id)\n",
    "trainer.create_model_card()\n",
    "\n",
    "# Push the results to the hub\n",
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = RobertaClassifier(num_labels=2, config=config)\n",
    "\n",
    "model_save_path = \"./nlp/ImperialIndians23/RobertaBaseUnprocessedDownsampledKeyword/final_model.pth\"\n",
    "model_state_dict = torch.load(model_save_path)\n",
    "\n",
    "loaded_model.load_state_dict(model_state_dict)\n",
    "\n",
    "loaded_model.eval()\n",
    "print(\"loaded..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Assuming dataset[\"valid\"] is already tokenized and ready for input\n",
    "valid_dataloader = DataLoader(\n",
    "    dataset[\"valid\"],\n",
    "    batch_size=1,\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"valid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "loaded_model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "loaded_model.to(device)\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():  # No need to track gradients during evaluation\n",
    "    for batch in tqdm(valid_dataloader):\n",
    "        # print(batch.keys())\n",
    "        # Move batch to the same device as the loaded_model\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        labels = batch.pop(\"labels\").detach().cpu().numpy()\n",
    "        outputs = loaded_model(**batch)\n",
    "        logits = outputs.logits if hasattr(outputs, \"logits\") else outputs[0]\n",
    "        preds = torch.argmax(logits, dim=-1).detach().cpu().numpy()\n",
    "\n",
    "        # Accumulate predictions and labels\n",
    "        all_preds.append(preds)\n",
    "        all_labels.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(all_preds) == len(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = [int(x) for x in all_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter(list(all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    precision_recall_fscore_support,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "gold = dataset[\"valid\"][\"label\"]\n",
    "t1p = precision_score(gold, all_preds)\n",
    "t1r = recall_score(gold, all_preds)\n",
    "t1f = f1_score(gold, all_preds)\n",
    "print(\"Precision:\", t1p)\n",
    "print(\"Recall:\", t1r)\n",
    "print(\"F1:\", t1f)\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 6 - Custom RoBERTa model - Processed Text (Downsampled) + Keyword\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    RobertaTokenizerFast,\n",
    "    RobertaForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    AutoConfig,\n",
    ")\n",
    "from huggingface_hub import HfFolder, notebook_login\n",
    "from tqdm import tqdm\n",
    "\n",
    "import wandb\n",
    "import os\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_fscore_support,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "from transformers import EvalPrediction\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import RobertaModel, RobertaTokenizer, AdamW\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "class RobertaClassifier(nn.Module):\n",
    "    def __init__(self, num_labels, config):\n",
    "        super(RobertaClassifier, self).__init__()\n",
    "        self.roberta = RobertaModel.from_pretrained(\"roberta-base\", config=config)\n",
    "        self.mapper = nn.Linear(\n",
    "            self.roberta.config.hidden_size * 2, self.roberta.config.hidden_size * 2\n",
    "        )\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.classifier = nn.Linear(self.roberta.config.hidden_size * 2, num_labels)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.config = config\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids,\n",
    "        attention_mask,\n",
    "        community_input_ids,\n",
    "        community_attention_mask,\n",
    "        labels=None,\n",
    "    ):\n",
    "        outputs = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        text_embedding = outputs[1]\n",
    "\n",
    "        # Process community keywords\n",
    "        community_outputs = self.roberta(\n",
    "            input_ids=community_input_ids, attention_mask=community_attention_mask\n",
    "        )\n",
    "        community_embedding = community_outputs[1]\n",
    "\n",
    "        # print(f\"Text embedding shape: {text_embedding.shape}\")\n",
    "        # print(f\"Community embedding shape: {community_embedding.shape}\")\n",
    "\n",
    "        # Concatenate\n",
    "        combined_embedding = torch.cat((text_embedding, community_embedding), dim=1)\n",
    "\n",
    "        mapped_embedding = self.mapper(combined_embedding)\n",
    "        # Apply dropout to the output of the mapper\n",
    "        dropped_embedding = self.dropout(mapped_embedding)\n",
    "\n",
    "        # Pass the result through the classifier to get logits\n",
    "        logits = self.classifier(dropped_embedding)\n",
    "\n",
    "        # Compute loss if labels are provided (during training)\n",
    "        if labels is not None:\n",
    "            loss = self.loss_fn(logits, labels)\n",
    "            return loss, logits\n",
    "        else:\n",
    "            return logits\n",
    "\n",
    "\n",
    "class CustomDataCollatorWithPadding(DataCollatorWithPadding):\n",
    "    def __call__(self, features):\n",
    "        batch = super().__call__(features)\n",
    "\n",
    "        community_input_ids = torch.stack(\n",
    "            [feature[\"community_input_ids\"] for feature in features]\n",
    "        )\n",
    "        community_attention_mask = torch.stack(\n",
    "            [feature[\"community_attention_mask\"] for feature in features]\n",
    "        )\n",
    "\n",
    "        padded_community_input_ids = self.pad_tensors(\n",
    "            community_input_ids, self.tokenizer.pad_token_id\n",
    "        )\n",
    "        padded_community_attention_mask = self.pad_tensors(community_attention_mask, 0)\n",
    "\n",
    "        batch[\"community_input_ids\"] = padded_community_input_ids\n",
    "        batch[\"community_attention_mask\"] = padded_community_attention_mask\n",
    "\n",
    "        return batch\n",
    "\n",
    "    def pad_tensors(self, tensors, pad_token_id):\n",
    "        max_length = max(t.size(0) for t in tensors)\n",
    "        # Pad each tensor to match the longest one\n",
    "        padded = torch.stack(\n",
    "            [\n",
    "                torch.cat(\n",
    "                    [\n",
    "                        t,\n",
    "                        torch.full(\n",
    "                            (max_length - t.size(0),), pad_token_id, dtype=t.dtype\n",
    "                        ),\n",
    "                    ]\n",
    "                )\n",
    "                for t in tensors\n",
    "            ]\n",
    "        )\n",
    "        return padded\n",
    "\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions.argmax(-1)\n",
    "    labels = p.label_ids\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds)\n",
    "    recall = recall_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds)\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"f1\": f1,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "    }\n",
    "\n",
    "\n",
    "HF_TOKEN = \"put your token here\"\n",
    "WANDB_TOKEN = \"put your token here\"\n",
    "\n",
    "# WANDB_TOKEN = userdata.get('WANDB_TOKEN')\n",
    "wandb.login(key=WANDB_TOKEN)\n",
    "\n",
    "model_id = \"roberta-base\"\n",
    "username = \"ImperialIndians23\"\n",
    "downsampled = True\n",
    "processed = True\n",
    "\n",
    "dataset_id = \"ImperialIndians23/nlp_cw_data\"\n",
    "run_name = f\"roberta - keyword\"\n",
    "\n",
    "if processed:\n",
    "    dataset_id += \"_processed\"\n",
    "    run_name += \" processed \"\n",
    "else:\n",
    "    dataset_id += \"_unprocessed\"\n",
    "    run_name += \" unprocessed \"\n",
    "\n",
    "if downsampled:\n",
    "    dataset_id += \"_downsampled\"\n",
    "    run_name += \"downsampled \"\n",
    "\n",
    "\n",
    "training_config = {\n",
    "    \"learning_rate\": 1e-5,\n",
    "    \"num_train_epochs\": 3,\n",
    "    \"weight_decay\": 0.01,\n",
    "    \"gradient_accumulation_steps\": 4,\n",
    "    \"per_device_train_batch_size\": 4,\n",
    "    \"per_device_eval_batch_size\": 2,\n",
    "    \"lr_scheduler_type\": \"inverse_sqrt\",\n",
    "    \"warmup_steps\": 500,\n",
    "    \"load_best_model_at_end\": True,\n",
    "    \"save_strategy\": \"epoch\",\n",
    "    \"evaluation_strategy\": \"epoch\",\n",
    "    \"metric_for_best_model\": \"f1\",\n",
    "}\n",
    "\n",
    "run_name += f\"- {training_config['num_train_epochs']} epochs\"\n",
    "\n",
    "\n",
    "repository_id = \"ImperialIndians23/RobertaBaseProcessedDownsampledKeywordDropout\"\n",
    "\n",
    "dataset = load_dataset(dataset_id)\n",
    "\n",
    "print(\"Processing the dataset...\")\n",
    "\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(model_id)\n",
    "\n",
    "\n",
    "def tokenize_data(batch):\n",
    "    # Tokenize the main text\n",
    "    text_encoding = tokenizer(\n",
    "        batch[\"text\"],\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    # Tokenize the community keyword\n",
    "    community_encoding = tokenizer(\n",
    "        batch[\"community\"],\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=64,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": text_encoding[\"input_ids\"],\n",
    "        \"attention_mask\": text_encoding[\"attention_mask\"],\n",
    "        \"community_input_ids\": community_encoding[\"input_ids\"],\n",
    "        \"community_attention_mask\": community_encoding[\"attention_mask\"],\n",
    "    }\n",
    "\n",
    "\n",
    "dataset[\"train\"] = dataset[\"train\"].map(tokenize_data, batched=True)\n",
    "dataset[\"valid\"] = dataset[\"valid\"].map(tokenize_data, batched=True)\n",
    "\n",
    "\n",
    "dataset[\"train\"].set_format(\n",
    "    \"torch\",\n",
    "    columns=[\n",
    "        \"input_ids\",\n",
    "        \"attention_mask\",\n",
    "        \"label\",\n",
    "        \"community_input_ids\",\n",
    "        \"community_attention_mask\",\n",
    "    ],\n",
    ")\n",
    "dataset[\"valid\"].set_format(\n",
    "    \"torch\",\n",
    "    columns=[\n",
    "        \"input_ids\",\n",
    "        \"attention_mask\",\n",
    "        \"label\",\n",
    "        \"community_input_ids\",\n",
    "        \"community_attention_mask\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "num_labels = 2\n",
    "class_names = [0, 1]\n",
    "print(f\"number of labels: {num_labels}\")\n",
    "print(f\"the labels: {class_names}\")\n",
    "\n",
    "# Create an id2label mapping\n",
    "id2label = {i: label for i, label in enumerate(class_names)}\n",
    "\n",
    "# Update the model's configuration with the id2label mapping\n",
    "config = AutoConfig.from_pretrained(model_id)\n",
    "config.update({\"id2label\": id2label})\n",
    "\n",
    "model = RobertaClassifier(num_labels=2, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=repository_id,\n",
    "    logging_dir=f\"{repository_id}/logs\",\n",
    "    logging_steps=10,\n",
    "    save_total_limit=3,\n",
    "    push_to_hub=True,\n",
    "    report_to=\"wandb\",\n",
    "    **training_config,\n",
    ")\n",
    "\n",
    "run = wandb.init(\n",
    "    project=\"nlp_cw\",\n",
    "    name=run_name,\n",
    "    # Track hyperparameters and run metadata\n",
    "    config=training_config,\n",
    ")\n",
    "\n",
    "\n",
    "data_collator = CustomDataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"valid\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "trainer.evaluate()\n",
    "\n",
    "# Save the tokenizer and create a model card\n",
    "tokenizer.save_pretrained(repository_id)\n",
    "trainer.create_model_card()\n",
    "\n",
    "# Push the results to the hub\n",
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = f\"/vol/bitbucket/rm1623/nlp/{repository_id}/final_model.pth\"\n",
    "\n",
    "torch.save(trainer.model.state_dict(), model_save_path)\n",
    "\n",
    "loaded_model = RobertaClassifier(num_labels=2, config=config)\n",
    "\n",
    "model_state_dict = torch.load(model_save_path)\n",
    "\n",
    "loaded_model.load_state_dict(model_state_dict)\n",
    "\n",
    "loaded_model.eval()\n",
    "print(\"Loaded...\")\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Assuming dataset[\"valid\"] is already tokenized and ready for input\n",
    "valid_dataloader = DataLoader(\n",
    "    dataset[\"valid\"],\n",
    "    batch_size=1,\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "loaded_model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "loaded_model.to(device)\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(valid_dataloader):\n",
    "        # Move batch to the same device as the loaded_model\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        labels = batch.pop(\"labels\").detach().cpu().numpy()\n",
    "        outputs = loaded_model(**batch)\n",
    "        logits = outputs.logits if hasattr(outputs, \"logits\") else outputs[0]\n",
    "        preds = torch.argmax(logits, dim=-1).detach().cpu().numpy()\n",
    "\n",
    "        # Accumulate predictions and labels\n",
    "        all_preds.append(preds)\n",
    "        all_labels.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    precision_recall_fscore_support,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "gold = dataset[\"valid\"][\"label\"]\n",
    "t1p = precision_score(gold, all_preds)\n",
    "t1r = recall_score(gold, all_preds)\n",
    "t1f = f1_score(gold, all_preds)\n",
    "print(\"Precision:\", t1p)\n",
    "print(\"Recall:\", t1r)\n",
    "print(\"F1:\", t1f)\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 7: Experiment 6 but with more epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    RobertaTokenizerFast,\n",
    "    RobertaForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    AutoConfig,\n",
    ")\n",
    "from huggingface_hub import HfFolder, notebook_login\n",
    "from tqdm import tqdm\n",
    "\n",
    "import wandb\n",
    "import os\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_fscore_support,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "from transformers import EvalPrediction\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import RobertaModel, RobertaTokenizer, AdamW\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "class RobertaClassifier(nn.Module):\n",
    "    def __init__(self, num_labels, config):\n",
    "        super(RobertaClassifier, self).__init__()\n",
    "        self.roberta = RobertaModel.from_pretrained(\"roberta-base\", config=config)\n",
    "        self.mapper = nn.Linear(\n",
    "            self.roberta.config.hidden_size * 2, self.roberta.config.hidden_size * 2\n",
    "        )\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.classifier = nn.Linear(self.roberta.config.hidden_size * 2, num_labels)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.config = config\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids,\n",
    "        attention_mask,\n",
    "        community_input_ids,\n",
    "        community_attention_mask,\n",
    "        labels=None,\n",
    "    ):\n",
    "        outputs = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        text_embedding = outputs[1]\n",
    "\n",
    "        # Process community keywords\n",
    "        community_outputs = self.roberta(\n",
    "            input_ids=community_input_ids, attention_mask=community_attention_mask\n",
    "        )\n",
    "        community_embedding = community_outputs[1]\n",
    "\n",
    "        # Concatenate\n",
    "        combined_embedding = torch.cat((text_embedding, community_embedding), dim=1)\n",
    "\n",
    "        mapped_embedding = self.mapper(combined_embedding)\n",
    "        # Apply dropout to the output of the mapper\n",
    "        dropped_embedding = self.dropout(mapped_embedding)\n",
    "\n",
    "        # Pass the result through the classifier to get logits\n",
    "        logits = self.classifier(dropped_embedding)\n",
    "\n",
    "        # Compute loss if labels are provided (during training)\n",
    "        if labels is not None:\n",
    "            loss = self.loss_fn(logits, labels)\n",
    "            return loss, logits\n",
    "        else:\n",
    "            return logits\n",
    "\n",
    "\n",
    "class CustomDataCollatorWithPadding(DataCollatorWithPadding):\n",
    "    def __call__(self, features):\n",
    "        batch = super().__call__(features)\n",
    "\n",
    "        community_input_ids = torch.stack(\n",
    "            [feature[\"community_input_ids\"] for feature in features]\n",
    "        )\n",
    "        community_attention_mask = torch.stack(\n",
    "            [feature[\"community_attention_mask\"] for feature in features]\n",
    "        )\n",
    "\n",
    "        padded_community_input_ids = self.pad_tensors(\n",
    "            community_input_ids, self.tokenizer.pad_token_id\n",
    "        )\n",
    "        padded_community_attention_mask = self.pad_tensors(community_attention_mask, 0)\n",
    "\n",
    "        batch[\"community_input_ids\"] = padded_community_input_ids\n",
    "        batch[\"community_attention_mask\"] = padded_community_attention_mask\n",
    "\n",
    "        return batch\n",
    "\n",
    "    def pad_tensors(self, tensors, pad_token_id):\n",
    "        max_length = max(t.size(0) for t in tensors)\n",
    "        # Pad each tensor to match the longest one\n",
    "        padded = torch.stack(\n",
    "            [\n",
    "                torch.cat(\n",
    "                    [\n",
    "                        t,\n",
    "                        torch.full(\n",
    "                            (max_length - t.size(0),), pad_token_id, dtype=t.dtype\n",
    "                        ),\n",
    "                    ]\n",
    "                )\n",
    "                for t in tensors\n",
    "            ]\n",
    "        )\n",
    "        return padded\n",
    "\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions.argmax(-1)\n",
    "    labels = p.label_ids\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds)\n",
    "    recall = recall_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds)\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"f1\": f1,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "    }\n",
    "\n",
    "\n",
    "HF_TOKEN = \"put your token here\"\n",
    "WANDB_TOKEN = \"put your token here\"\n",
    "\n",
    "# WANDB_TOKEN = userdata.get('WANDB_TOKEN')\n",
    "wandb.login(key=WANDB_TOKEN)\n",
    "\n",
    "model_id = \"roberta-base\"\n",
    "username = \"ImperialIndians23\"\n",
    "downsampled = True\n",
    "processed = True\n",
    "\n",
    "dataset_id = \"ImperialIndians23/nlp_cw_data\"\n",
    "run_name = f\"roberta - keyword\"\n",
    "\n",
    "if processed:\n",
    "    dataset_id += \"_processed\"\n",
    "    run_name += \" processed \"\n",
    "else:\n",
    "    dataset_id += \"_unprocessed\"\n",
    "    run_name += \" unprocessed \"\n",
    "\n",
    "if downsampled:\n",
    "    dataset_id += \"_downsampled\"\n",
    "    run_name += \"downsampled \"\n",
    "\n",
    "\n",
    "training_config = {\n",
    "    \"learning_rate\": 1e-5,\n",
    "    \"num_train_epochs\": 7,\n",
    "    \"weight_decay\": 0.01,\n",
    "    \"gradient_accumulation_steps\": 4,\n",
    "    \"per_device_train_batch_size\": 2,\n",
    "    \"per_device_eval_batch_size\": 2,\n",
    "    \"lr_scheduler_type\": \"inverse_sqrt\",\n",
    "    \"warmup_steps\": 500,\n",
    "    \"load_best_model_at_end\": True,\n",
    "    \"save_strategy\": \"epoch\",\n",
    "    \"evaluation_strategy\": \"epoch\",\n",
    "    \"metric_for_best_model\": \"f1\",\n",
    "}\n",
    "\n",
    "run_name += f\"- {training_config['num_train_epochs']} epochs\"\n",
    "\n",
    "repository_id = \"ImperialIndians23/RobertaBaseProcessedDownsampledKeywordDropoutE7\"\n",
    "\n",
    "dataset = load_dataset(dataset_id)\n",
    "\n",
    "print(\"Processing the dataset...\")\n",
    "\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(model_id)\n",
    "\n",
    "\n",
    "def tokenize_data(batch):\n",
    "    # Tokenize the main text\n",
    "    text_encoding = tokenizer(\n",
    "        batch[\"text\"],\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    # Tokenize the community keyword\n",
    "    # Assuming each item has a single community keyword for simplicity\n",
    "    community_encoding = tokenizer(\n",
    "        batch[\"community\"],\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=64,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": text_encoding[\"input_ids\"],\n",
    "        \"attention_mask\": text_encoding[\"attention_mask\"],\n",
    "        \"community_input_ids\": community_encoding[\"input_ids\"],\n",
    "        \"community_attention_mask\": community_encoding[\"attention_mask\"],\n",
    "    }\n",
    "\n",
    "\n",
    "dataset[\"train\"] = dataset[\"train\"].map(tokenize_data, batched=True)\n",
    "dataset[\"valid\"] = dataset[\"valid\"].map(tokenize_data, batched=True)\n",
    "\n",
    "\n",
    "dataset[\"train\"].set_format(\n",
    "    \"torch\",\n",
    "    columns=[\n",
    "        \"input_ids\",\n",
    "        \"attention_mask\",\n",
    "        \"label\",\n",
    "        \"community_input_ids\",\n",
    "        \"community_attention_mask\",\n",
    "    ],\n",
    ")\n",
    "dataset[\"valid\"].set_format(\n",
    "    \"torch\",\n",
    "    columns=[\n",
    "        \"input_ids\",\n",
    "        \"attention_mask\",\n",
    "        \"label\",\n",
    "        \"community_input_ids\",\n",
    "        \"community_attention_mask\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "num_labels = 2\n",
    "class_names = [0, 1]\n",
    "print(f\"number of labels: {num_labels}\")\n",
    "print(f\"the labels: {class_names}\")\n",
    "\n",
    "# Create an id2label mapping\n",
    "id2label = {i: label for i, label in enumerate(class_names)}\n",
    "\n",
    "# Update the model's configuration with the id2label mapping\n",
    "config = AutoConfig.from_pretrained(model_id)\n",
    "config.update({\"id2label\": id2label})\n",
    "\n",
    "model = RobertaClassifier(num_labels=2, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=repository_id,\n",
    "    logging_dir=f\"{repository_id}/logs\",\n",
    "    logging_steps=10,\n",
    "    save_total_limit=3,\n",
    "    push_to_hub=True,\n",
    "    report_to=\"wandb\",\n",
    "    **training_config,\n",
    ")\n",
    "\n",
    "run = wandb.init(\n",
    "    project=\"nlp_cw\",\n",
    "    name=run_name,\n",
    "    # Track hyperparameters and run metadata\n",
    "    config=training_config,\n",
    ")\n",
    "\n",
    "\n",
    "data_collator = CustomDataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"valid\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "trainer.evaluate()\n",
    "\n",
    "# Save the tokenizer and create a model card\n",
    "tokenizer.save_pretrained(repository_id)\n",
    "trainer.create_model_card()\n",
    "\n",
    "# Push the results to the hub\n",
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 8 - Unprocessed Text + Back Translation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    RobertaTokenizerFast,\n",
    "    RobertaForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    AutoConfig,\n",
    ")\n",
    "from huggingface_hub import HfFolder, notebook_login\n",
    "from tqdm import tqdm\n",
    "\n",
    "import wandb\n",
    "import os\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_fscore_support,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "from transformers import EvalPrediction\n",
    "\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions.argmax(-1)\n",
    "    labels = p.label_ids\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds)\n",
    "    recall = recall_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds)\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"f1\": f1,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "    }\n",
    "\n",
    "\n",
    "HF_TOKEN = \"put your token here\"\n",
    "WANDB_TOKEN = \"put your token here\"\n",
    "\n",
    "# WANDB_TOKEN = userdata.get('WANDB_TOKEN')\n",
    "wandb.login(key=WANDB_TOKEN)\n",
    "\n",
    "model_id = \"roberta-base\"\n",
    "username = \"ImperialIndians23\"\n",
    "downsampled = False\n",
    "processed = False\n",
    "augmented = True\n",
    "\n",
    "dataset_id = \"ImperialIndians23/nlp_cw_data\"\n",
    "run_name = f\"roberta - keyword\"\n",
    "\n",
    "if processed:\n",
    "    dataset_id += \"_processed\"\n",
    "    run_name += \" processed \"\n",
    "else:\n",
    "    dataset_id += \"_unprocessed\"\n",
    "    run_name += \" unprocessed \"\n",
    "\n",
    "if downsampled:\n",
    "    dataset_id += \"_downsampled\"\n",
    "    run_name += \"downsampled \"\n",
    "\n",
    "if augmented:\n",
    "    dataset_id += \"_augmented\"\n",
    "    run_name += \"augmented \"\n",
    "\n",
    "\n",
    "training_config = {\n",
    "    \"learning_rate\": 1e-5,\n",
    "    \"num_train_epochs\": 3,\n",
    "    \"weight_decay\": 0.01,\n",
    "    \"gradient_accumulation_steps\": 4,\n",
    "    \"per_device_train_batch_size\": 4,\n",
    "    \"per_device_eval_batch_size\": 2,\n",
    "    \"lr_scheduler_type\": \"inverse_sqrt\",\n",
    "    \"warmup_steps\": 500,\n",
    "    \"load_best_model_at_end\": True,\n",
    "    \"save_strategy\": \"epoch\",\n",
    "    \"evaluation_strategy\": \"epoch\",\n",
    "    \"metric_for_best_model\": \"f1\",\n",
    "}\n",
    "\n",
    "run_name += f\"- {training_config['num_train_epochs']} epochs\"\n",
    "\n",
    "repository_id = \"ImperialIndians23/RobertaBaseUnprocessedAugmented\"\n",
    "\n",
    "dataset = load_dataset(dataset_id)\n",
    "\n",
    "print(\"Processing the dataset...\")\n",
    "\n",
    "# Training\n",
    "train_dataset = dataset[\"train\"]\n",
    "\n",
    "# Validation dataset\n",
    "val_dataset = dataset[\"valid\"]\n",
    "\n",
    "# Preprocessing\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(model_id)\n",
    "\n",
    "\n",
    "# This function tokenizes the input text using the RoBERTa tokenizer.\n",
    "# It applies padding and truncation to ensure that all sequences have the same length (512 tokens).\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True, max_length=512)\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize, batched=True, batch_size=len(train_dataset))\n",
    "val_dataset = val_dataset.map(tokenize, batched=True, batch_size=len(val_dataset))\n",
    "\n",
    "\n",
    "train_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "val_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "num_labels = 2\n",
    "class_names = [0, 1]\n",
    "print(f\"number of labels: {num_labels}\")\n",
    "print(f\"the labels: {class_names}\")\n",
    "\n",
    "id2label = {i: label for i, label in enumerate(class_names)}\n",
    "\n",
    "# Update the model's configuration with the id2label mapping\n",
    "config = AutoConfig.from_pretrained(model_id)\n",
    "config.update({\"id2label\": id2label})\n",
    "\n",
    "\n",
    "model = RobertaForSequenceClassification.from_pretrained(model_id, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=repository_id,\n",
    "    logging_dir=f\"{repository_id}/logs\",\n",
    "    logging_steps=10,\n",
    "    save_total_limit=3,\n",
    "    push_to_hub=True,\n",
    "    report_to=\"wandb\",\n",
    "    **training_config,\n",
    ")\n",
    "\n",
    "run = wandb.init(\n",
    "    project=\"nlp_cw\",\n",
    "    name=run_name,\n",
    "    # Track hyperparameters and run metadata\n",
    "    config=training_config,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "trainer.evaluate()\n",
    "\n",
    "# Save the tokenizer and create a model card\n",
    "tokenizer.save_pretrained(repository_id)\n",
    "trainer.create_model_card()\n",
    "\n",
    "# Push the results to the hub\n",
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 9 - Unprocessed + Synonym Aug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    RobertaTokenizerFast,\n",
    "    RobertaForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    AutoConfig,\n",
    ")\n",
    "from huggingface_hub import HfFolder, notebook_login\n",
    "from tqdm import tqdm\n",
    "\n",
    "import wandb\n",
    "import os\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_fscore_support,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "from transformers import EvalPrediction\n",
    "\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions.argmax(-1)\n",
    "    labels = p.label_ids\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds)\n",
    "    recall = recall_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds)\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"f1\": f1,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "    }\n",
    "\n",
    "\n",
    "HF_TOKEN = \"put your token here\"\n",
    "WANDB_TOKEN = \"put your token here\"\n",
    "\n",
    "# WANDB_TOKEN = userdata.get('WANDB_TOKEN')\n",
    "wandb.login(key=WANDB_TOKEN)\n",
    "\n",
    "model_id = \"roberta-base\"\n",
    "username = \"ImperialIndians23\"\n",
    "downsampled = False\n",
    "processed = False\n",
    "augmented = True\n",
    "synonym_augmented = True\n",
    "\n",
    "dataset_id = \"ImperialIndians23/nlp_cw_data\"\n",
    "run_name = f\"roberta - keyword\"\n",
    "\n",
    "if processed:\n",
    "    dataset_id += \"_processed\"\n",
    "    run_name += \" processed \"\n",
    "else:\n",
    "    dataset_id += \"_unprocessed\"\n",
    "    run_name += \" unprocessed \"\n",
    "\n",
    "if downsampled:\n",
    "    dataset_id += \"_downsampled\"\n",
    "    run_name += \"downsampled \"\n",
    "\n",
    "if augmented:\n",
    "    dataset_id += \"_augmented\"\n",
    "    run_name += \"augmented \"\n",
    "\n",
    "if synonym_augmented:\n",
    "    dataset_id += \"_synonym\"\n",
    "    run_name += \"synonym \"\n",
    "\n",
    "print(\"Dataset:\", dataset_id)\n",
    "\n",
    "training_config = {\n",
    "    \"learning_rate\": 1e-5,\n",
    "    \"num_train_epochs\": 3,\n",
    "    \"weight_decay\": 0.01,\n",
    "    \"gradient_accumulation_steps\": 4,\n",
    "    \"per_device_train_batch_size\": 4,\n",
    "    \"per_device_eval_batch_size\": 2,\n",
    "    \"lr_scheduler_type\": \"inverse_sqrt\",\n",
    "    \"warmup_steps\": 500,\n",
    "    \"load_best_model_at_end\": True,\n",
    "    \"save_strategy\": \"epoch\",\n",
    "    \"evaluation_strategy\": \"epoch\",\n",
    "    \"metric_for_best_model\": \"f1\",\n",
    "}\n",
    "\n",
    "run_name += f\"- {training_config['num_train_epochs']} epochs\"\n",
    "\n",
    "repository_id = \"ImperialIndians23/RobertaBaseUnprocessedAugmentedSynonym\"\n",
    "\n",
    "dataset = load_dataset(dataset_id)\n",
    "\n",
    "print(\"Processing the dataset...\")\n",
    "\n",
    "# Training\n",
    "train_dataset = dataset[\"train\"]\n",
    "\n",
    "# Validation dataset\n",
    "val_dataset = dataset[\"valid\"]\n",
    "\n",
    "# Preprocessing\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(model_id)\n",
    "\n",
    "\n",
    "# This function tokenizes the input text using the RoBERTa tokenizer.\n",
    "# It applies padding and truncation to ensure that all sequences have the same length (512 tokens).\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True, max_length=512)\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize, batched=True, batch_size=len(train_dataset))\n",
    "val_dataset = val_dataset.map(tokenize, batched=True, batch_size=len(val_dataset))\n",
    "\n",
    "train_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "val_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "num_labels = 2\n",
    "class_names = [0, 1]\n",
    "print(f\"number of labels: {num_labels}\")\n",
    "print(f\"the labels: {class_names}\")\n",
    "\n",
    "id2label = {i: label for i, label in enumerate(class_names)}\n",
    "\n",
    "# Update the model's configuration with the id2label mapping\n",
    "config = AutoConfig.from_pretrained(model_id)\n",
    "config.update({\"id2label\": id2label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RobertaForSequenceClassification.from_pretrained(model_id, config=config)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=repository_id,\n",
    "    logging_dir=f\"{repository_id}/logs\",\n",
    "    logging_steps=10,\n",
    "    save_total_limit=3,\n",
    "    push_to_hub=True,\n",
    "    report_to=\"wandb\",\n",
    "    **training_config,\n",
    ")\n",
    "\n",
    "run = wandb.init(\n",
    "    project=\"nlp_cw\",\n",
    "    name=run_name,\n",
    "    # Track hyperparameters and run metadata\n",
    "    config=training_config,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "trainer.evaluate()\n",
    "\n",
    "# Save the tokenizer and create a model card\n",
    "tokenizer.save_pretrained(repository_id)\n",
    "trainer.create_model_card()\n",
    "\n",
    "# Push the results to the hub\n",
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 10 - Unprocessed + Back Translation + Synonym Aug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    RobertaTokenizerFast,\n",
    "    RobertaForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    AutoConfig,\n",
    ")\n",
    "from huggingface_hub import HfFolder, notebook_login\n",
    "from tqdm import tqdm\n",
    "\n",
    "import wandb\n",
    "import os\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_fscore_support,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "from transformers import EvalPrediction\n",
    "\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions.argmax(-1)\n",
    "    labels = p.label_ids\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds)\n",
    "    recall = recall_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds)\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"f1\": f1,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "    }\n",
    "\n",
    "\n",
    "HF_TOKEN = \"put your token here\"\n",
    "WANDB_TOKEN = \"put your token here\"\n",
    "\n",
    "# WANDB_TOKEN = userdata.get('WANDB_TOKEN')\n",
    "wandb.login(key=WANDB_TOKEN)\n",
    "\n",
    "model_id = \"roberta-base\"\n",
    "username = \"ImperialIndians23\"\n",
    "downsampled = False\n",
    "processed = False\n",
    "augmented = True\n",
    "double_augmented = True\n",
    "\n",
    "dataset_id = \"ImperialIndians23/nlp_cw_data\"\n",
    "run_name = f\"roberta - keyword\"\n",
    "\n",
    "if processed:\n",
    "    dataset_id += \"_processed\"\n",
    "    run_name += \" processed \"\n",
    "else:\n",
    "    dataset_id += \"_unprocessed\"\n",
    "    run_name += \" unprocessed \"\n",
    "\n",
    "if downsampled:\n",
    "    dataset_id += \"_downsampled\"\n",
    "    run_name += \"downsampled \"\n",
    "\n",
    "if augmented:\n",
    "    dataset_id += \"_augmented\"\n",
    "    run_name += \"augmented \"\n",
    "\n",
    "if double_augmented:\n",
    "    dataset_id += \"_both\"\n",
    "    run_name += \"both \"\n",
    "\n",
    "\n",
    "training_config = {\n",
    "    \"learning_rate\": 1e-5,\n",
    "    \"num_train_epochs\": 3,\n",
    "    \"weight_decay\": 0.01,\n",
    "    \"gradient_accumulation_steps\": 4,\n",
    "    \"per_device_train_batch_size\": 4,\n",
    "    \"per_device_eval_batch_size\": 2,\n",
    "    \"lr_scheduler_type\": \"inverse_sqrt\",\n",
    "    \"warmup_steps\": 500,\n",
    "    \"load_best_model_at_end\": True,\n",
    "    \"save_strategy\": \"epoch\",\n",
    "    \"evaluation_strategy\": \"epoch\",\n",
    "    \"metric_for_best_model\": \"f1\",\n",
    "}\n",
    "\n",
    "run_name += f\"- {training_config['num_train_epochs']} epochs\"\n",
    "\n",
    "repository_id = \"ImperialIndians23/RobertaBaseUnprocessedAugmentedBoth\"\n",
    "\n",
    "dataset = load_dataset(dataset_id)\n",
    "\n",
    "print(\"Processing the dataset...\")\n",
    "\n",
    "# Training\n",
    "train_dataset = dataset[\"train\"]\n",
    "\n",
    "# Validation dataset\n",
    "val_dataset = dataset[\"valid\"]\n",
    "\n",
    "# Preprocessing\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(model_id)\n",
    "\n",
    "\n",
    "# This function tokenizes the input text using the RoBERTa tokenizer.\n",
    "# It applies padding and truncation to ensure that all sequences have the same length (512 tokens).\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True, max_length=512)\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize, batched=True, batch_size=len(train_dataset))\n",
    "val_dataset = val_dataset.map(tokenize, batched=True, batch_size=len(val_dataset))\n",
    "\n",
    "train_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "val_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "num_labels = 2\n",
    "class_names = [0, 1]\n",
    "print(f\"number of labels: {num_labels}\")\n",
    "print(f\"the labels: {class_names}\")\n",
    "\n",
    "id2label = {i: label for i, label in enumerate(class_names)}\n",
    "\n",
    "# Update the model's configuration with the id2label mapping\n",
    "config = AutoConfig.from_pretrained(model_id)\n",
    "config.update({\"id2label\": id2label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RobertaForSequenceClassification.from_pretrained(model_id, config=config)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=repository_id,\n",
    "    logging_dir=f\"{repository_id}/logs\",\n",
    "    logging_steps=10,\n",
    "    save_total_limit=3,\n",
    "    push_to_hub=True,\n",
    "    report_to=\"wandb\",\n",
    "    **training_config,\n",
    ")\n",
    "\n",
    "run = wandb.init(\n",
    "    project=\"nlp_cw\",\n",
    "    name=run_name,\n",
    "    # Track hyperparameters and run metadata\n",
    "    config=training_config,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "trainer.evaluate()\n",
    "\n",
    "# Save the tokenizer and create a model card\n",
    "tokenizer.save_pretrained(repository_id)\n",
    "trainer.create_model_card()\n",
    "\n",
    "# Push the results to the hub\n",
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do final model predictions on `dev` set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score 1 model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels2file(p, outf_path):\n",
    "    with open(outf_path, \"w\") as outf:\n",
    "        for pi in p:\n",
    "            outf.write(\",\".join([str(pi)]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"ImperialIndians23/nlp_cw_data_unprocessed\")\n",
    "valid_dataset = dataset[\"valid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "\n",
    "classifier = pipeline(\"text-classification\", repository_id)\n",
    "\n",
    "batch_size = 8\n",
    "predictions = []\n",
    "\n",
    "# Retrieve all texts from the dataset\n",
    "texts = [example[\"text\"] for example in valid_dataset]\n",
    "\n",
    "# Process texts in batches\n",
    "for i in range(0, len(texts), batch_size):\n",
    "    batch_texts = texts[i : i + batch_size]\n",
    "    batch_results = classifier(batch_texts)\n",
    "\n",
    "    # Extract and store predictions from results\n",
    "    batch_predictions = [result[\"label\"] for result in batch_results]\n",
    "    predictions.extend(batch_predictions)\n",
    "\n",
    "labels2file(predictions, os.path.join(\"res/\", \"task1.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold = dataset[\"valid\"][\"label\"]\n",
    "labels2file(gold, os.path.join(\"ref/\", \"task1.txt\"))\n",
    "\n",
    "input_dir = \"./\"\n",
    "output_dir = \"./\"\n",
    "\n",
    "# define gold data path\n",
    "ref_dir = os.path.join(input_dir, \"ref\")\n",
    "\n",
    "# define submission data path\n",
    "submission_dir = os.path.join(input_dir, \"res\")\n",
    "files = os.listdir(submission_dir)\n",
    "outf = open(os.path.join(output_dir, \"scores.txt\"), \"w\")\n",
    "\n",
    "# evaluating on task 1\n",
    "if \"task1.txt\" in files:\n",
    "    task1_res = []\n",
    "    task1_gold = []\n",
    "    with open(os.path.join(submission_dir, \"task1.txt\")) as f:\n",
    "        for line in f:\n",
    "            task1_res.append(int(line.strip()))\n",
    "    with open(os.path.join(ref_dir, \"task1.txt\")) as f:\n",
    "        for line in f:\n",
    "            task1_gold.append(int(line.strip()))\n",
    "    # task 1 scores\n",
    "    t1p = precision_score(task1_gold, task1_res)\n",
    "    t1r = recall_score(task1_gold, task1_res)\n",
    "    t1f = f1_score(task1_gold, task1_res)\n",
    "    # task1\n",
    "    outf.write(\"task1_precision:\" + str(t1p) + \"\\n\")\n",
    "    outf.write(\"task1_recall:\" + str(t1r) + \"\\n\")\n",
    "    outf.write(\"task1_f1:\" + str(t1f) + \"\\n\")\n",
    "\n",
    "outf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score all models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_fscore_support,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "\n",
    "def scorer(repository_id, task1_gold, valid_dataset):\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Evaluating {repository_id.removeprefix('ImperialIndians23/')}\")\n",
    "    classifier = pipeline(\"text-classification\", repository_id)\n",
    "\n",
    "    batch_size = 8\n",
    "    task1_res = []\n",
    "\n",
    "    # Retrieve all texts from the dataset\n",
    "    texts = [example[\"text\"] for example in valid_dataset]\n",
    "\n",
    "    # Process texts in batches\n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        batch_texts = texts[i : i + batch_size]\n",
    "        batch_results = classifier(batch_texts)\n",
    "\n",
    "        # Extract and store predictions from results\n",
    "        batch_predictions = [result[\"label\"] for result in batch_results]\n",
    "        task1_res.extend(batch_predictions)\n",
    "    t1p = precision_score(task1_gold, task1_res)\n",
    "    t1r = recall_score(task1_gold, task1_res)\n",
    "    t1f = f1_score(task1_gold, task1_res)\n",
    "    print(\"Precision:\", t1p)\n",
    "    print(\"Recall:\", t1r)\n",
    "    print(\"F1:\", t1f)\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"ImperialIndians23/nlp_cw_data_processed\")\n",
    "valid_dataset = dataset[\"valid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repository_ids = [\n",
    "    \"ImperialIndians23/RobertaBaseProcessedDownsampled\",\n",
    "    \"ImperialIndians23/RobertaBaseProcessed\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold = dataset[\"valid\"][\"label\"]\n",
    "\n",
    "for repository_id in repository_ids:\n",
    "    scorer(repository_id, gold, valid_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unprocessed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"ImperialIndians23/nlp_cw_data_unprocessed\")\n",
    "valid_dataset = dataset[\"valid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repository_ids = [\n",
    "    \"ImperialIndians23/RobertaBaseUnprocessedAugmented\",\n",
    "    \"ImperialIndians23/RobertaBaseUnprocessedDownsampled\",\n",
    "    \"ImperialIndians23/RobertaBaseUnprocessed\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold = valid_dataset[\"label\"]\n",
    "\n",
    "for repository_id in repository_ids:\n",
    "    scorer(repository_id, gold, valid_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Augmented\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repository_ids = [\n",
    "    \"ImperialIndians23/RobertaBaseUnprocessedAugmentedSynonym\",\n",
    "    \"ImperialIndians23/RobertaBaseUnprocessedAugmented\",\n",
    "    \"ImperialIndians23/RobertaBaseUnprocessedAugmentedBoth\",\n",
    "]\n",
    "gold = valid_dataset[\"label\"]\n",
    "\n",
    "for repository_id in repository_ids:\n",
    "    scorer(repository_id, gold, valid_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for tough sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "def scorer(repository_id, task1_gold, valid_dataset):\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Evaluating {repository_id.removeprefix('ImperialIndians23/')}\")\n",
    "    classifier = pipeline(\"text-classification\", model=repository_id, device=\"cuda\")\n",
    "\n",
    "    batch_size = 8\n",
    "    task1_res = []\n",
    "    wrong_samples = []\n",
    "\n",
    "    texts = [example[\"text\"] for example in valid_dataset]\n",
    "    parids = [example[\"par_id\"] for example in valid_dataset]\n",
    "    labels = task1_gold\n",
    "\n",
    "    # Process texts in batches\n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        batch_texts = texts[i : i + batch_size]\n",
    "        batch_parids = parids[i : i + batch_size]\n",
    "\n",
    "        batch_labels = labels[i : i + batch_size]\n",
    "        batch_results = classifier(batch_texts)\n",
    "\n",
    "        # Extract predictions from results\n",
    "        batch_predictions = [result[\"label\"] for result in batch_results]\n",
    "        task1_res.extend(batch_predictions)\n",
    "\n",
    "        # Check for wrong predictions and store them\n",
    "        for j, (pred, real) in enumerate(zip(batch_predictions, batch_labels)):\n",
    "            if pred != real:\n",
    "                wrong_sample = (batch_parids[j], batch_texts[j], real)\n",
    "                wrong_samples.append(wrong_sample)\n",
    "\n",
    "    # Metrics\n",
    "    t1p = precision_score(task1_gold, task1_res)\n",
    "    t1r = recall_score(task1_gold, task1_res)\n",
    "    t1f = f1_score(task1_gold, task1_res)\n",
    "\n",
    "    print(\"Precision:\", t1p)\n",
    "    print(\"Recall:\", t1r)\n",
    "    print(\"F1:\", t1f)\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    print(\"Some wrongly classified samples:\")\n",
    "    for parid, text, real_label in wrong_samples[:5]:\n",
    "        print(f\"ParID: {parid} Text: {text}, Real Label: {real_label}\")\n",
    "    return wrong_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"ImperialIndians23/nlp_cw_data_unprocessed\")\n",
    "valid_dataset = dataset[\"valid\"]\n",
    "repository_id = \"ImperialIndians23/RobertaBaseUnprocessedAugmented\"\n",
    "gold = valid_dataset[\"label\"]\n",
    "\n",
    "ws = scorer(repository_id, gold, valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lengths = [len(text) for _, text, _ in ws]\n",
    "labels = [label for _, _, label in ws]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(lengths, bins=20, alpha=0.7, label=labels)\n",
    "plt.title(\"Histogram of Text Lengths of Wrong Detections\")\n",
    "plt.xlabel(\"Length of Text\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend(title=\"Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "all_texts_lengths = [len(example[\"text\"]) for example in valid_dataset]\n",
    "wrong_texts_lengths = [len(text) for _, text, _ in ws]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(all_texts_lengths, bins=50, alpha=0.5, label=\"All Texts\")\n",
    "plt.hist(wrong_texts_lengths, bins=50, alpha=0.5, label=\"Wrongly Classified Texts\")\n",
    "plt.xlabel(\"Text Length\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Text Lengths vs. Wrongly Classified Texts\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "median_length = np.median(wrong_texts_lengths)\n",
    "average_length = np.mean(wrong_texts_lengths)\n",
    "percentile_25 = np.percentile(wrong_texts_lengths, 25)\n",
    "percentile_75 = np.percentile(wrong_texts_lengths, 75)\n",
    "print(median_length, average_length, percentile_25, percentile_75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Q1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "\n",
    "def scorer(repository_id, task1_gold, valid_dataset):\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Evaluating {repository_id.removeprefix('ImperialIndians23/')}\")\n",
    "    classifier = pipeline(\"text-classification\", model=repository_id, device=0)\n",
    "\n",
    "    batch_size = 8\n",
    "    task1_res = []\n",
    "    wrong_samples = [] \n",
    "    orig_label_preds = (\n",
    "        []\n",
    "    )  \n",
    "\n",
    "    texts = [example[\"text\"] for example in valid_dataset]\n",
    "    parids = [example[\"par_id\"] for example in valid_dataset]\n",
    "    labels = task1_gold\n",
    "    orig_labels_list = [example[\"orig_label\"] for example in valid_dataset]\n",
    "\n",
    "    # Process texts in batches\n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        batch_texts = texts[i : i + batch_size]\n",
    "        batch_parids = parids[i : i + batch_size]\n",
    "        batch_labels = labels[i : i + batch_size]\n",
    "        batch_orig_labels = orig_labels_list[i : i + batch_size]\n",
    "        batch_results = classifier(batch_texts)\n",
    "\n",
    "        # Extract predictions from results\n",
    "        # for result in batch_results:\n",
    "        #     print(result, type(result))\n",
    "        batch_predictions = [int(result[\"label\"]) for result in batch_results]\n",
    "        task1_res.extend(batch_predictions)\n",
    "\n",
    "        # Check for wrong predictions and assign original label predictions\n",
    "        for j, (pred, real, orig_label) in enumerate(\n",
    "            zip(batch_predictions, batch_labels, batch_orig_labels)\n",
    "        ):\n",
    "            if str(pred) == str(real):\n",
    "                orig_label_preds.append(orig_label)\n",
    "            else:\n",
    "                wrong_sample = (batch_parids[j], batch_texts[j], real)\n",
    "                wrong_samples.append(wrong_sample)\n",
    "                # Assign incorrect original label based on the binary prediction\n",
    "                if pred == \"1\":  # Incorrectly predicted as patronizing\n",
    "                    incorrect_orig_label = random.choice([2, 3, 4])\n",
    "                else:  # Incorrectly predicted as not patronizing\n",
    "                    incorrect_orig_label = random.choice([0, 1])\n",
    "                orig_label_preds.append(incorrect_orig_label)\n",
    "\n",
    "    # Metrics\n",
    "    t1p = precision_score(labels, task1_res, pos_label=1, average=\"binary\")\n",
    "    t1r = recall_score(labels, task1_res, pos_label=1, average=\"binary\")\n",
    "    t1f = f1_score(labels, task1_res, pos_label=1, average=\"binary\")\n",
    "\n",
    "    print(\"Binary Classification Metrics:\")\n",
    "    print(\"Precision:\", t1p)\n",
    "    print(\"Recall:\", t1r)\n",
    "    print(\"F1:\", t1f)\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    # Calculate and print F1 scores for original labels\n",
    "    orig_f1_scores = {}\n",
    "    for label in set(orig_labels_list):\n",
    "        bin_labels = [1 if l == label else 0 for l in orig_labels_list]\n",
    "        bin_preds = [1 if p == label else 0 for p in orig_label_preds]\n",
    "        orig_f1_scores[label] = f1_score(bin_labels, bin_preds)\n",
    "\n",
    "    print(\"Original Label F1 Scores:\", orig_f1_scores)\n",
    "\n",
    "    return wrong_samples, orig_f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "valid_dataset = load_from_disk(\"./nlp_cw_data_valid_with_orig_labels\")\n",
    "repository_id = \"ImperialIndians23/RobertaBaseUnprocessedAugmented\"\n",
    "gold = valid_dataset[\"label\"]\n",
    "\n",
    "ws, f1_scores = scorer(repository_id, gold, valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"green\", \"blue\", \"red\", \"purple\", \"orange\"]  # One color per label\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "labels, scores = zip(*sorted(f1_scores.items()))\n",
    "bars = plt.bar(labels, scores, color=colors)\n",
    "\n",
    "legend_elements = [\n",
    "    plt.Line2D([0], [0], color=color, lw=4, label=f\"Level {label}\")\n",
    "    for label, color in zip(labels, colors)\n",
    "]\n",
    "plt.legend(handles=legend_elements, title=\"Original Labels\")\n",
    "\n",
    "plt.xlabel(\"Original Labels\")\n",
    "plt.ylabel(\"F1 Score\")\n",
    "plt.title(\"F1 Scores for Original Labels\")\n",
    "plt.xticks(labels)\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Q3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "def scorer(repository_id, task1_gold, valid_dataset):\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Evaluating {repository_id.removeprefix('ImperialIndians23/')}\")\n",
    "    classifier = pipeline(\"text-classification\", model=repository_id, device=\"cuda\")\n",
    "\n",
    "    batch_size = 8\n",
    "    community_wise_results = defaultdict(lambda: {\"predictions\": [], \"labels\": []})\n",
    "    wrong_samples = [] \n",
    "\n",
    "    texts = [example[\"text\"] for example in valid_dataset]\n",
    "    parids = [example[\"par_id\"] for example in valid_dataset]\n",
    "    labels = task1_gold  # Assuming task1_gold contains the actual labels\n",
    "    communities = [example[\"community\"] for example in valid_dataset]\n",
    "\n",
    "    # Process texts in batches\n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        batch_texts = texts[i : i + batch_size]\n",
    "        batch_parids = parids[i : i + batch_size]\n",
    "        batch_labels = labels[i : i + batch_size]\n",
    "        batch_communities = communities[i : i + batch_size]\n",
    "        batch_results = classifier(batch_texts)\n",
    "\n",
    "        # Extract predictions from results\n",
    "        batch_predictions = [result[\"label\"] for result in batch_results]\n",
    "\n",
    "        # Group by community\n",
    "        for j, (prediction, label, community) in enumerate(\n",
    "            zip(batch_predictions, batch_labels, batch_communities)\n",
    "        ):\n",
    "            community_wise_results[community][\"predictions\"].append(prediction)\n",
    "            community_wise_results[community][\"labels\"].append(label)\n",
    "\n",
    "            # Check for wrong predictions and store them\n",
    "            if prediction != label:\n",
    "                wrong_sample = (batch_parids[j], batch_texts[j], label)\n",
    "                wrong_samples.append(wrong_sample)\n",
    "\n",
    "    # Community-wise Metrics\n",
    "    community_f1_scores = {}\n",
    "    for community, results in community_wise_results.items():\n",
    "        community_f1_scores[community] = f1_score(\n",
    "            results[\"labels\"], results[\"predictions\"], average=\"weighted\"\n",
    "        )\n",
    "        print(f\"Community: {community}\")\n",
    "        print(\"F1:\", community_f1_scores[community])\n",
    "\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    return community_f1_scores, wrong_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "valid_dataset = load_from_disk(\"./nlp_cw_data_valid_with_orig_labels\")\n",
    "repository_id = \"ImperialIndians23/RobertaBaseUnprocessedAugmented\"\n",
    "gold = valid_dataset[\"label\"]\n",
    "\n",
    "f1_scores, ws = scorer(repository_id, gold, valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "community_f1_data = pd.DataFrame(\n",
    "    list(f1_scores.items()), columns=[\"Community\", \"F1 Score\"]\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=\"Community\", y=\"F1 Score\", data=community_f1_data, palette=\"viridis\")\n",
    "\n",
    "plt.xlabel(\"Community\")\n",
    "plt.ylabel(\"F1 Score\")\n",
    "plt.title(\"Community-wise F1 Scores\")\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
